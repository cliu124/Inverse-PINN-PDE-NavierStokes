{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v77mk3x5Ljlg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.interpolate import griddata\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.sparse import lil_matrix, csr_matrix\n",
        "from scipy.sparse.linalg import lsqr\n",
        "import time\n",
        "\n",
        "# Physical Parameters\n",
        "C1 = 1.0    # Nonlinear term coefficient (u·∇u)\n",
        "C2 = 0.01   # Viscosity coefficient (ν)\n",
        "\n",
        "def add_noise(data, noise_level=0.0):\n",
        "    \"\"\"Add component-wise Gaussian noise\"\"\"\n",
        "    if noise_level == 0.0:\n",
        "        return data.copy()\n",
        "    noisy_data = data.copy()\n",
        "    for i in range(data.shape[1]):\n",
        "        std = np.std(data[:, i])\n",
        "        noisy_data[:, i] = data[:, i] + noise_level * std * np.random.randn(data.shape[0])\n",
        "    return noisy_data\n",
        "\n",
        "def load_data(mat_path, target_t=1.0):\n",
        "    \"\"\"Load and prepare cylinder wake data at specific time\"\"\"\n",
        "    if not os.path.exists(mat_path):\n",
        "        raise FileNotFoundError(f\"Data file not found at: {mat_path}\")\n",
        "    data = loadmat(mat_path)\n",
        "    X_star = data['X_star']\n",
        "    U_star = data['U_star']\n",
        "    p_star = data['p_star']\n",
        "    t_all = data['t'].flatten()\n",
        "    t_idx = np.argmin(np.abs(t_all - target_t))\n",
        "    x, y = X_star[:, 0], X_star[:, 1]\n",
        "    u, v = U_star[:, 0], U_star[:, 1]\n",
        "    p = p_star[:, t_idx].flatten()\n",
        "    T = np.full_like(x, target_t)\n",
        "    return np.column_stack((x, y, T)), np.column_stack((u, v, p)), x, y, p\n",
        "\n",
        "def preprocess_data(X, Y):\n",
        "    \"\"\"Normalize data using StandardScaler\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    Y_norm = scaler.fit_transform(Y)\n",
        "    return Y_norm, scaler\n",
        "\n",
        "def train_mlp(X, Y_norm):\n",
        "    \"\"\"Train MLP regressor with tanh activation\"\"\"\n",
        "    model = MLPRegressor(hidden_layer_sizes=(60, 40), activation='tanh', solver='adam',\n",
        "                        max_iter=1000, tol=1e-6, random_state=42)\n",
        "    model.fit(X, Y_norm)\n",
        "    return model\n",
        "\n",
        "def estimate_parameters(x, y, u, v, p):\n",
        "    \"\"\"Physics-informed parameter estimation\"\"\"\n",
        "    grid_size = 150\n",
        "    x_lin = np.linspace(-2, 10, grid_size)\n",
        "    y_lin = np.linspace(-4, 4, grid_size)\n",
        "    Xg, Yg = np.meshgrid(x_lin, y_lin)\n",
        "    pts = np.column_stack((x, y))\n",
        "\n",
        "    # Interpolate with masking near cylinder\n",
        "    Zu = griddata(pts, u, (Xg, Yg), method='linear')\n",
        "    Zv = griddata(pts, v, (Xg, Yg), method='linear')\n",
        "    Zp = griddata(pts, p, (Xg, Yg), method='linear')\n",
        "    cylinder_mask = (Xg**2 + Yg**2) < 0.25\n",
        "    Zu[cylinder_mask] = np.nan\n",
        "    Zv[cylinder_mask] = np.nan\n",
        "    Zp[cylinder_mask] = np.nan\n",
        "\n",
        "    # Compute derivatives\n",
        "    dx = x_lin[1] - x_lin[0]\n",
        "    dy = y_lin[1] - y_lin[0]\n",
        "    dudx, dudy = np.gradient(Zu, dx, dy)\n",
        "    dvdx, dvdy = np.gradient(Zv, dx, dy)\n",
        "    dpdx, dpdy = np.gradient(Zp, dx, dy)\n",
        "    d2udx2 = np.gradient(dudx, dx, axis=1)\n",
        "    d2udy2 = np.gradient(dudy, dy, axis=0)\n",
        "    d2vdx2 = np.gradient(dvdx, dx, axis=1)\n",
        "    d2vdy2 = np.gradient(dvdy, dy, axis=0)\n",
        "\n",
        "    # Filter valid points\n",
        "    valid_mask = ~np.isnan(Zu.ravel())\n",
        "    u_flat = Zu.ravel()[valid_mask]\n",
        "    v_flat = Zv.ravel()[valid_mask]\n",
        "\n",
        "    # Build linear system\n",
        "    num_points = len(u_flat)\n",
        "    A = lil_matrix((2*num_points, 2))\n",
        "    b = np.zeros(2*num_points)\n",
        "\n",
        "    # Formulate Navier-Stokes equations\n",
        "    conv_u = u_flat * dudx.ravel()[valid_mask] + v_flat * dudy.ravel()[valid_mask]\n",
        "    diff_u = d2udx2.ravel()[valid_mask] + d2udy2.ravel()[valid_mask]\n",
        "    conv_v = u_flat * dvdx.ravel()[valid_mask] + v_flat * dvdy.ravel()[valid_mask]\n",
        "    diff_v = d2vdx2.ravel()[valid_mask] + d2vdy2.ravel()[valid_mask]\n",
        "\n",
        "    A[:num_points, 0] = conv_u.reshape(-1, 1)\n",
        "    A[:num_points, 1] = -diff_u.reshape(-1, 1)\n",
        "    b[:num_points] = -dpdx.ravel()[valid_mask]\n",
        "\n",
        "    A[num_points:, 0] = conv_v.reshape(-1, 1)\n",
        "    A[num_points:, 1] = -diff_v.reshape(-1, 1)\n",
        "    b[num_points:] = -dpdy.ravel()[valid_mask]\n",
        "\n",
        "    # Solve sparse system\n",
        "    result = lsqr(csr_matrix(A), b, atol=1e-4, btol=1e-4)\n",
        "    return result[0], result[4]\n",
        "\n",
        "def plot_velocity_comparison(x, y, u_pred, v_pred, u_true, v_true, title, output_dir, noise_level):\n",
        "    \"\"\"Create comparison plots with consistent color scaling\"\"\"\n",
        "    grid_size = 300\n",
        "    x_lin = np.linspace(-2, 10, grid_size)\n",
        "    y_lin = np.linspace(-4, 4, grid_size)\n",
        "    Xg, Yg = np.meshgrid(x_lin, y_lin)\n",
        "    pts = np.column_stack((x, y))\n",
        "\n",
        "    # Interpolate with common scale\n",
        "    Zu_pred = griddata(pts, u_pred, (Xg, Yg), method='linear')\n",
        "    Zv_pred = griddata(pts, v_pred, (Xg, Yg), method='linear')\n",
        "    Zu_true = griddata(pts, u_true, (Xg, Yg), method='linear')\n",
        "    Zv_true = griddata(pts, v_true, (Xg, Yg), method='linear')\n",
        "\n",
        "    # Use symmetric scaling based on true data\n",
        "    max_val = max(np.nanmax(np.abs(Zu_true)), np.nanmax(np.abs(Zv_true)))\n",
        "    vmin, vmax = -max_val, max_val\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Predicted velocities\n",
        "    im1 = axes[0,0].imshow(Zu_pred, extent=(-2,10,-4,4), cmap='coolwarm',\n",
        "                          vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
        "    axes[0,0].set_title('Predicted u-velocity')\n",
        "    fig.colorbar(im1, ax=axes[0,0])\n",
        "    axes[0,0].add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "\n",
        "    im2 = axes[0,1].imshow(Zv_pred, extent=(-2,10,-4,4), cmap='coolwarm',\n",
        "                          vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
        "    axes[0,1].set_title('Predicted v-velocity')\n",
        "    fig.colorbar(im2, ax=axes[0,1])\n",
        "    axes[0,1].add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "\n",
        "    # True velocities\n",
        "    im3 = axes[1,0].imshow(Zu_true, extent=(-2,10,-4,4), cmap='coolwarm',\n",
        "                          vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
        "    axes[1,0].set_title('True u-velocity')\n",
        "    fig.colorbar(im3, ax=axes[1,0])\n",
        "    axes[1,0].add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "\n",
        "    im4 = axes[1,1].imshow(Zv_true, extent=(-2,10,-4,4), cmap='coolwarm',\n",
        "                          vmin=vmin, vmax=vmax, origin='lower', aspect='auto')\n",
        "    axes[1,1].set_title('True v-velocity')\n",
        "    fig.colorbar(im4, ax=axes[1,1])\n",
        "    axes[1,1].add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(os.path.join(output_dir, f'velocity_comparison_{noise_level}.png'),\n",
        "               dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_pressure_comparison(x, y, p_true, p_pred, title, output_dir, noise_level):\n",
        "    \"\"\"Create pressure comparison plot\"\"\"\n",
        "    grid_size = 200\n",
        "    x_lin = np.linspace(-2, 10, grid_size)\n",
        "    y_lin = np.linspace(-4, 4, grid_size)\n",
        "    Xg, Yg = np.meshgrid(x_lin, y_lin)\n",
        "    pts = np.column_stack((x, y))\n",
        "\n",
        "    Z_pred = griddata(pts, p_pred, (Xg, Yg), method='linear')\n",
        "    Z_true = griddata(pts, p_true, (Xg, Yg), method='linear')\n",
        "\n",
        "    # Center pressure by removing mean difference\n",
        "    pressure_diff = np.nanmean(Z_true) - np.nanmean(Z_pred)\n",
        "    Z_pred += pressure_diff\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Predicted pressure\n",
        "    pcm1 = ax1.contourf(Xg, Yg, Z_pred, levels=50, cmap='RdYlBu')\n",
        "    ax1.add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "    ax1.set_title('Predicted Pressure')\n",
        "    ax1.set_aspect('equal')\n",
        "    fig.colorbar(pcm1, ax=ax1)\n",
        "\n",
        "    # True pressure\n",
        "    pcm2 = ax2.contourf(Xg, Yg, Z_true, levels=50, cmap='RdYlBu')\n",
        "    ax2.add_patch(plt.Circle((0, 0), 0.5, color='gray', fill=True))\n",
        "    ax2.set_title('True Pressure')\n",
        "    ax2.set_aspect('equal')\n",
        "    fig.colorbar(pcm2, ax=ax2)\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(os.path.join(output_dir, f'pressure_comparison_{noise_level}.png'),\n",
        "               dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "def calculate_metrics(u_true, v_true, p_true, u_pred, v_pred, p_pred):\n",
        "    \"\"\"Calculate quantitative performance metrics\"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    # Velocity errors\n",
        "    metrics['u_mae'] = np.mean(np.abs(u_true - u_pred))\n",
        "    metrics['u_rmse'] = np.sqrt(np.mean((u_true - u_pred)**2))\n",
        "    metrics['u_max'] = np.max(np.abs(u_true))\n",
        "\n",
        "    metrics['v_mae'] = np.mean(np.abs(v_true - v_pred))\n",
        "    metrics['v_rmse'] = np.sqrt(np.mean((v_true - v_pred)**2))\n",
        "    metrics['v_max'] = np.max(np.abs(v_true))\n",
        "\n",
        "    # Pressure errors (considering constant offset)\n",
        "    p_offset = np.mean(p_true) - np.mean(p_pred)\n",
        "    p_pred_corr = p_pred + p_offset\n",
        "    metrics['p_mae'] = np.mean(np.abs(p_true - p_pred_corr))\n",
        "    metrics['p_rmse'] = np.sqrt(np.mean((p_true - p_pred_corr)**2))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def generate_results_table(results):\n",
        "    \"\"\"Generate publication-quality results table\"\"\"\n",
        "    latex = \"\\\\begin{table}[ht]\\n\"\n",
        "    latex += \"\\\\centering\\n\"\n",
        "    latex += \"\\\\caption{Parameter estimation results}\\n\"\n",
        "    latex += \"\\\\begin{tabular}{|c|c|c|c|c|c|}\\n\"\n",
        "    latex += \"\\\\hline\\n\"\n",
        "    latex += \"Noise Level & C1 Estimate & C2 Estimate & u-RMSE & v-RMSE & p-RMSE \\\\\\\\\\n\"\n",
        "    latex += \"\\\\hline\\n\"\n",
        "\n",
        "    for res in results:\n",
        "        latex += f\"{res['Noise Level']*100:.1f}\\% & {res['C1_estimated']:.5f} & {res['C2_estimated']:.5f} & \"\n",
        "        latex += f\"{res['u_RMSE']:.2e} & {res['v_RMSE']:.2e} & {res['p_RMSE']:.2e} \\\\\\\\\\n\"\n",
        "        latex += \"\\\\hline\\n\"\n",
        "\n",
        "    latex += \"\\\\end{tabular}\\n\"\n",
        "    latex += \"\\\\end{table}\"\n",
        "\n",
        "    # Add PDE equations\n",
        "    clean_data = next(r for r in results if r['Noise Level'] == 0.0)\n",
        "    noise_data = next(r for r in results if r['Noise Level'] == 0.01)\n",
        "\n",
        "    latex += \"\\n\\n\\\\begin{align*}\\n\"\n",
        "    latex += \"\\\\text{Correct PDE:} & \\\\quad u_t + (uu_x + vu_y) = -p_x + 0.01(u_{xx} + u_{yy}) \\\\\\\\\\n\"\n",
        "    latex += \"& \\\\quad v_t + (uv_x + vv_y) = -p_y + 0.01(v_{xx} + v_{yy}) \\\\\\\\[10pt]\\n\"\n",
        "    latex += f\"\\\\text{{Identified (clean):}} & \\\\quad u_t + {clean_data['C1_estimated']:.3f}(uu_x + vu_y) = -p_x + {clean_data['C2_estimated']:.5f}(u_{{xx}} + u_{{yy}}) \\\\\\\\\\n\"\n",
        "    latex += f\"& \\\\quad v_t + {clean_data['C1_estimated']:.3f}(uv_x + vv_y) = -p_y + {clean_data['C2_estimated']:.5f}(v_{{xx}} + v_{{yy}}) \\\\\\\\[10pt]\\n\"\n",
        "    latex += f\"\\\\text{{Identified (1\\\\% noise):}} & \\\\quad u_t + {noise_data['C1_estimated']:.3f}(uu_x + vu_y) = -p_x + {noise_data['C2_estimated']:.5f}(u_{{xx}} + u_{{yy}}) \\\\\\\\\\n\"\n",
        "    latex += f\"& \\\\quad v_t + {noise_data['C1_estimated']:.3f}(uv_x + vv_y) = -p_y + {noise_data['C2_estimated']:.5f}(v_{{xx}} + v_{{yy}})\\n\"\n",
        "    latex += \"\\\\end{align*}\"\n",
        "\n",
        "    return latex\n",
        "\n",
        "def main():\n",
        "    # Create output directory on Desktop\n",
        "    output_dir = os.path.join(os.path.expanduser('~'), 'Desktop', 'NextStep_Results')\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Use your exact file path\n",
        "    mat_path = r'C:\\Users\\sauja\\Downloads\\cylinder_nektar_wake.mat'\n",
        "\n",
        "    # Verify file exists\n",
        "    if not os.path.exists(mat_path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Data file not found at: {mat_path}\\n\"\n",
        "            \"Please verify:\\n\"\n",
        "            \"1. The file exists at this location\\n\"\n",
        "            \"2. The filename is EXACTLY 'cylinder_nektar_wake.mat'\\n\"\n",
        "            \"3. You have read permissions\"\n",
        "        )\n",
        "\n",
        "    # Load data\n",
        "    X, Y, x, y, p_true = load_data(mat_path, target_t=1.0)\n",
        "    u_true, v_true = Y[:, 0], Y[:, 1]\n",
        "\n",
        "    # Test multiple noise levels\n",
        "    noise_levels = [0.0, 0.01, 0.05, 0.1, 0.5]\n",
        "    results = []\n",
        "\n",
        "    for noise_level in noise_levels:\n",
        "        start_time = time.time()\n",
        "        print(f\"Processing noise level: {noise_level*100:.1f}%\")\n",
        "\n",
        "        # Add noise only to velocities\n",
        "        Y_noisy = Y.copy()\n",
        "        Y_noisy[:, 0] = add_noise(Y[:, 0:1], noise_level).flatten()\n",
        "        Y_noisy[:, 1] = add_noise(Y[:, 1:2], noise_level).flatten()\n",
        "\n",
        "        # Preprocess and train\n",
        "        Y_norm, scaler = preprocess_data(X, Y_noisy)\n",
        "        model = train_mlp(X, Y_norm)\n",
        "\n",
        "        # Predict and denormalize\n",
        "        Y_pred = scaler.inverse_transform(model.predict(X))\n",
        "        u_pred, v_pred, p_pred = Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2]\n",
        "\n",
        "        # Estimate parameters\n",
        "        try:\n",
        "            params, residual_norm = estimate_parameters(x, y, u_pred, v_pred, p_pred)\n",
        "            c1_est, c2_est = params\n",
        "        except Exception as e:\n",
        "            print(f\"Parameter estimation failed: {str(e)}\")\n",
        "            c1_est, c2_est = np.nan, np.nan\n",
        "            residual_norm = np.nan\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics = calculate_metrics(u_true, v_true, p_true, u_pred, v_pred, p_pred)\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'Noise Level': noise_level,\n",
        "            'C1_estimated': c1_est,\n",
        "            'C2_estimated': c2_est,\n",
        "            'u_MAE': metrics['u_mae'],\n",
        "            'u_RMSE': metrics['u_rmse'],\n",
        "            'v_MAE': metrics['v_mae'],\n",
        "            'v_RMSE': metrics['v_rmse'],\n",
        "            'p_MAE': metrics['p_mae'],\n",
        "            'p_RMSE': metrics['p_rmse'],\n",
        "            'Residual': residual_norm\n",
        "        })\n",
        "\n",
        "        # Save plots for key noise levels\n",
        "        if noise_level in [0.0, 0.01, 0.1]:\n",
        "            plot_velocity_comparison(\n",
        "                x, y, u_pred, v_pred, u_true, v_true,\n",
        "                f\"Cylinder Wake at t=1.0 | Noise={noise_level*100:.1f}%\",\n",
        "                output_dir, noise_level\n",
        "            )\n",
        "\n",
        "            plot_pressure_comparison(\n",
        "                x, y, p_true, p_pred,\n",
        "                f\"Cylinder Wake at t=1.0 | Noise={noise_level*100:.1f}%\",\n",
        "                output_dir, noise_level\n",
        "            )\n",
        "\n",
        "        print(f\"Completed in {time.time()-start_time:.1f} seconds\")\n",
        "\n",
        "    # Save results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_csv = os.path.join(output_dir, 'parameter_results.csv')\n",
        "    results_df.to_csv(results_csv, index=False)\n",
        "\n",
        "    # Generate LaTeX table\n",
        "    latex_table = generate_results_table(results)\n",
        "    with open(os.path.join(output_dir, 'results_table.tex'), 'w') as f:\n",
        "        f.write(latex_table)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nResults Summary:\")\n",
        "    print(results_df[['Noise Level', 'C1_estimated', 'C2_estimated',\n",
        "                     'u_RMSE', 'v_RMSE', 'p_RMSE']].to_string())\n",
        "\n",
        "    print(f\"\\nResults saved to: {output_dir}\")\n",
        "    print(f\"CSV file: {results_csv}\")\n",
        "    print(f\"LaTeX table: {os.path.join(output_dir, 'results_table.tex')}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}