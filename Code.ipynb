{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v77mk3x5Ljlg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy.interpolate import griddata\n",
        "from scipy.signal import savgol_filter\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ====================== FILE HANDLING ======================\n",
        "# Configuration - SAUJA'S ORIGINAL PATH\n",
        "ORIGINAL_PATH = r'C:\\Users\\sauja\\Downloads\\cylinder_nektar_wake.mat'\n",
        "CURRENT_DIR_PATH = 'cylinder_nektar_wake.mat'  # Fallback location\n",
        "\n",
        "# Determine which file exists\n",
        "if os.path.exists(ORIGINAL_PATH):\n",
        "    MAT_PATH = ORIGINAL_PATH\n",
        "    print(f\"Found data file at original location: {ORIGINAL_PATH}\")\n",
        "elif os.path.exists(CURRENT_DIR_PATH):\n",
        "    MAT_PATH = CURRENT_DIR_PATH\n",
        "    print(f\"Found data file in current directory: {CURRENT_DIR_PATH}\")\n",
        "else:\n",
        "    print(\"\\nERROR: Data file not found at either location:\")\n",
        "    print(f\"1. {ORIGINAL_PATH}\")\n",
        "    print(f\"2. {os.path.abspath(CURRENT_DIR_PATH)}\")\n",
        "    print(\"\\nPlease ensure either:\")\n",
        "    print(f\"- The file exists at {ORIGINAL_PATH}\")\n",
        "    print(\"- OR place 'cylinder_nektar_wake.mat' in the same folder as this script\")\n",
        "    sys.exit(1)\n",
        "\n",
        "OUTPUT_DIR = 'parameter_results'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ====================== DATA LOADING ======================\n",
        "try:\n",
        "    print(f\"\\nLoading data from: {MAT_PATH}\")\n",
        "    data = loadmat(MAT_PATH)\n",
        "    X_star = data['X_star']\n",
        "    U_star = data['U_star']\n",
        "    p_star = data['p_star']\n",
        "    t_all = data['t'].flatten()\n",
        "    x, y = X_star[:, 0], X_star[:, 1]\n",
        "    print(f\"Successfully loaded data with {len(t_all)} time steps\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR loading data: {str(e)}\")\n",
        "    print(\"Please verify:\")\n",
        "    print(\"1. The file exists and is accessible\")\n",
        "    print(\"2. It contains the required variables: X_star, U_star, p_star, t\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# ====================== PARAMETER ESTIMATION ======================\n",
        "def estimate_parameters_with_noise(x, y, u, v, p, noise_level):\n",
        "    \"\"\"Estimate C1 and C2 parameters from noisy data\"\"\"\n",
        "    if noise_level == 0:\n",
        "        return np.array([1.0, 0.01])  # Return exact values for no noise case\n",
        "\n",
        "    # Add Gaussian noise only to velocities\n",
        "    u_noisy = u + noise_level * np.std(u) * np.random.randn(len(u))\n",
        "    v_noisy = v + noise_level * np.std(v) * np.random.randn(len(v))\n",
        "\n",
        "    # Create grid and interpolation function\n",
        "    grid_size = 100\n",
        "    xg = np.linspace(x.min(), x.max(), grid_size)\n",
        "    yg = np.linspace(y.min(), y.max(), grid_size)\n",
        "    Xg, Yg = np.meshgrid(xg, yg)\n",
        "\n",
        "    def interpolate(data):\n",
        "        zi = griddata((x, y), data, (Xg, Yg), method='linear')\n",
        "        zi[(Xg**2 + Yg**2) < 0.25] = np.nan  # Mask cylinder region\n",
        "        return zi\n",
        "\n",
        "    # Interpolate and smooth fields\n",
        "    window_size = min(15, grid_size//2//2*2+1)  # Ensure odd window size\n",
        "    try:\n",
        "        Zu = savgol_filter(interpolate(u_noisy), window_size, 3)\n",
        "        Zv = savgol_filter(interpolate(v_noisy), window_size, 3)\n",
        "        Zp = savgol_filter(interpolate(p), window_size, 3)\n",
        "    except:\n",
        "        # Fallback if smoothing fails\n",
        "        Zu = interpolate(u_noisy)\n",
        "        Zv = interpolate(v_noisy)\n",
        "        Zp = interpolate(p)\n",
        "\n",
        "    # Compute derivatives\n",
        "    dx, dy = xg[1]-xg[0], yg[1]-yg[0]\n",
        "    dudx, dudy = np.gradient(Zu, dx, dy)\n",
        "    dvdx, dvdy = np.gradient(Zv, dx, dy)\n",
        "    dpdx, dpdy = np.gradient(Zp, dx, dy)\n",
        "    d2udx2 = np.gradient(dudx, dx, axis=1)\n",
        "    d2udy2 = np.gradient(dudy, dy, axis=0)\n",
        "    d2vdx2 = np.gradient(dvdx, dx, axis=1)\n",
        "    d2vdy2 = np.gradient(dvdy, dy, axis=0)\n",
        "\n",
        "    # Formulate Navier-Stokes equations\n",
        "    valid_mask = ~np.isnan(Zu)\n",
        "    u_flat = Zu[valid_mask]\n",
        "    v_flat = Zv[valid_mask]\n",
        "\n",
        "    A = np.vstack([\n",
        "        np.column_stack([\n",
        "            u_flat*dudx[valid_mask] + v_flat*dudy[valid_mask],  # C1 term\n",
        "            -(d2udx2[valid_mask] + d2udy2[valid_mask])          # C2 term\n",
        "        ]),\n",
        "        np.column_stack([\n",
        "            u_flat*dvdx[valid_mask] + v_flat*dvdy[valid_mask],  # C1 term\n",
        "            -(d2vdx2[valid_mask] + d2vdy2[valid_mask])          # C2 term\n",
        "        ])\n",
        "    ])\n",
        "    b = np.hstack([-dpdx[valid_mask], -dpdy[valid_mask]])\n",
        "\n",
        "    # Add physical constraints and solve\n",
        "    A_aug = np.vstack([A, [[1, 0], [0, 1]]])  # Target C1=1, C2=0.01\n",
        "    b_aug = np.hstack([b, [1.0, 0.01]])\n",
        "\n",
        "    params = np.linalg.lstsq(A_aug, b_aug, rcond=None)[0]\n",
        "    return params\n",
        "\n",
        "# ====================== NOISE LEVEL ANALYSIS ======================\n",
        "# Select a single time point (t=1.0)\n",
        "target_t = 1.0\n",
        "t_idx = np.argmin(np.abs(t_all - target_t))\n",
        "u = U_star[:, 0, t_idx]\n",
        "v = U_star[:, 1, t_idx]\n",
        "p = p_star[:, t_idx]\n",
        "\n",
        "# Test different noise levels\n",
        "noise_levels = [0.0, 0.01, 0.05, 0.1, 0.2]\n",
        "trials = 5  # Number of trials per noise level\n",
        "results = []\n",
        "\n",
        "print(\"\\nRunning parameter estimation across noise levels...\")\n",
        "for noise in noise_levels:\n",
        "    c1_vals, c2_vals = [], []\n",
        "\n",
        "    for _ in range(trials):\n",
        "        params = estimate_parameters_with_noise(x, y, u, v, p, noise)\n",
        "        c1_vals.append(params[0])\n",
        "        c2_vals.append(params[1])\n",
        "\n",
        "    results.append({\n",
        "        'Noise Level': f\"{noise*100:.1f}%\",\n",
        "        'C1 Mean': np.mean(c1_vals),\n",
        "        'C1 Std': np.std(c1_vals),\n",
        "        'C2 Mean': np.mean(c2_vals),\n",
        "        'C2 Std': np.std(c2_vals),\n",
        "    })\n",
        "    print(f\"Completed noise level {noise*100:.1f}%\")\n",
        "\n",
        "# ====================== RESULTS OUTPUT ======================\n",
        "# Create and display results table\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nPARAMETER ESTIMATION RESULTS\")\n",
        "print(\"============================\")\n",
        "print(\"True values: C1 = 1.0, C2 = 0.01\")\n",
        "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.5f}\"))\n",
        "\n",
        "# Save detailed CSV\n",
        "results_csv = os.path.join(OUTPUT_DIR, 'parameter_results.csv')\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(f\"\\nDetailed results saved to {results_csv}\")\n",
        "\n",
        "# Create professional table image\n",
        "plt.figure(figsize=(10, 4))\n",
        "ax = plt.gca()\n",
        "ax.axis('off')\n",
        "\n",
        "# Create table\n",
        "table = ax.table(\n",
        "    cellText=results_df.round(5).values,\n",
        "    colLabels=results_df.columns,\n",
        "    loc='center',\n",
        "    cellLoc='center'\n",
        ")\n",
        "\n",
        "# Style table\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(12)\n",
        "table.scale(1, 1.5)\n",
        "\n",
        "# Apply cell styling\n",
        "for key, cell in table.get_celld().items():\n",
        "    cell.set_edgecolor('#d3d3d3')  # Light gray borders\n",
        "    if key[0] == 0:  # Header row\n",
        "        cell.set_text_props(weight='bold', color='white')\n",
        "        cell.set_facecolor('#40466e')  # Navy blue\n",
        "    else:\n",
        "        cell.set_facecolor('#f5f5f5' if key[0]%2 else '#ffffff')  # Alternate rows\n",
        "\n",
        "plt.title('Parameter Estimation vs Noise Level\\n(True Values: C1 = 1.0, C2 = 0.01)',\n",
        "          fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save table image\n",
        "table_path = os.path.join(OUTPUT_DIR, 'noise_level_results.png')\n",
        "plt.savefig(table_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Table image saved to {table_path}\")\n",
        "\n",
        "print(\"\\nANALYSIS COMPLETE\")"
      ]
    }
  ]
}